# A Focused Study on Sequence Length for Dialogue Summarization

For more details, please find our paper on arXiv

[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2209.11910)

# Requirements

We test the code with python 3.7 and below requirements.
```
pip install -r requirements.txt
```

# Dialogue Summarization Demo

In this part, we provide a demo to generated summary given a dialogue and desired output lengths

First, download the trained model from xxx and put it in folder xxx

Demo with different output lengths
```
bash xxx
```

# Training and Testing Code

Baseline model
```
bash xxx
```

LA-BART model with ground-truth summary length
```
bash xxx
```

## References

If you find our work useful, please consider citing our work.

```
@article{wang2022focused,
  title={A Focused Study on Sequence Length for Dialogue Summarization},
  author={Wang, Bin and Zhang, Chen and Wei, Chengwei and Li, Haizhou},
  journal={arXiv preprint arXiv:2209.11910},
  year={2022}
}
```

```
@article{to update with proceedings,
  title={==},
  author={==},
  journal={==},
  year={==}
}
```

Contact to Bin Wang at [bwang28c@gmail.com](mailto:bwang28c@gmail.com) for any issues.